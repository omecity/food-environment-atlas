{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "515b0399-db77-4e59-bd57-f4c12781b0a4",
   "metadata": {},
   "source": [
    "## Equidistant train-test split and k-fold cross-validation\n",
    "\n",
    "The purpose of having a customized train/test split and cross-fold validation routine is to stratify the data by location without using the 'State' identifier. Stratifying county data by state introduces imbalances for states with a disproportionately high number of metro counties, or states with few total counties.\n",
    "\n",
    "This notebook iterates through a permuted list of row indices, successively adding one index to the test set and m indices to the training set, where m is the value of the 'training_rows_per_test_row' variable and the desired test-size is 1/(1 + m). The m training indices are of the m counties closest to the test county, which have not already been added to the training or test sets. This process also stratifies the data by a specified list of categorical variables, by first slicing the data according to each possible combination of categorical data values, and then applying the distance-preserving split to each slice. Unscaled training data and test data are then saved to a .csv file before applying a StandardScaler and proceeding with cross-validation.\n",
    "\n",
    "For cross-validation, the above process is applied to the training set k - 1 times to subdivide into k subsets of equal size (we have chosen k = 5). From this, training and holdout sets are defined, and these are saved to .csv files along with the final test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8449eba1-85ca-48ce-9e9b-416aebfda986",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(689503320)\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27efe320-926a-4c2c-90da-5a4f9130b3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/data_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b145933-d76f-4b5d-8be5-c3989bfff682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include calculated data identifying the 20 closest neighbors to each county\n",
    "closest_neighboring_counties = pd.read_csv('../data/closest_neighboring_counties.csv')\n",
    "MAX_NEIGHBORS = len(closest_neighboring_counties.columns) - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23fbd0af-ca01-4050-a512-f76736865101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3142 entries, 0 to 3141\n",
      "Data columns (total 66 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   State                      3142 non-null   object \n",
      " 1   County                     3142 non-null   object \n",
      " 2   SNAPSPTH17                 3142 non-null   float64\n",
      " 3   REDEMP_SNAPS17             3142 non-null   float64\n",
      " 4   PCT_SNAP17                 3142 non-null   float64\n",
      " 5   PC_SNAPBEN17               3142 non-null   float64\n",
      " 6   PCT_NSLP17                 3142 non-null   float64\n",
      " 7   PCT_SBP17                  3142 non-null   float64\n",
      " 8   PCT_SFSP17                 3142 non-null   float64\n",
      " 9   PCT_WIC17                  3142 non-null   float64\n",
      " 10  PCT_CACFP17                3142 non-null   float64\n",
      " 11  PCT_OBESE_ADULTS17         3142 non-null   float64\n",
      " 12  GROCPTH16                  3142 non-null   float64\n",
      " 13  SUPERCPTH16                3142 non-null   float64\n",
      " 14  CONVSPTH16                 3142 non-null   float64\n",
      " 15  SPECSPTH16                 3142 non-null   float64\n",
      " 16  WICSPTH16                  3142 non-null   float64\n",
      " 17  FFRPTH16                   3142 non-null   float64\n",
      " 18  FSRPTH16                   3142 non-null   float64\n",
      " 19  PC_WIC_REDEMP16            3142 non-null   float64\n",
      " 20  REDEMP_WICS16              3142 non-null   float64\n",
      " 21  PCT_WICINFANTCHILD16       3142 non-null   float64\n",
      " 22  PCT_WICWOMEN16             3142 non-null   float64\n",
      " 23  RECFACPTH16                3142 non-null   float64\n",
      " 24  FIPS                       3142 non-null   int64  \n",
      " 25  POVRATE15                  3142 non-null   float64\n",
      " 26  PERPOV10                   3142 non-null   int64  \n",
      " 27  METRO13                    3142 non-null   int64  \n",
      " 28  MEDHHINC15                 3142 non-null   float64\n",
      " 29  FDPIR15                    3142 non-null   int64  \n",
      " 30  PCT_LACCESS_POP15          3142 non-null   float64\n",
      " 31  PCT_LACCESS_LOWI15         3142 non-null   float64\n",
      " 32  PCT_LACCESS_HHNV15         3142 non-null   float64\n",
      " 33  FOODINSEC_15_17            3142 non-null   float64\n",
      " 34  VLFOODSEC_15_17            3142 non-null   float64\n",
      " 35  PopulationEstimate2017     3142 non-null   int64  \n",
      " 36  LogPopulationEstimate2017  3142 non-null   float64\n",
      " 37  LogTransformedFDPIR15      3142 non-null   float64\n",
      " 38  LogTransformedGROCPTH16    3142 non-null   float64\n",
      " 39  LogTransformedSUPERCPTH16  3142 non-null   float64\n",
      " 40  LogTransformedCONVSPTH16   3142 non-null   float64\n",
      " 41  LogTransformedSPECSPTH16   3142 non-null   float64\n",
      " 42  LogTransformedWICSPTH16    3142 non-null   float64\n",
      " 43  LogTransformedFFRPTH16     3142 non-null   float64\n",
      " 44  LogTransformedFSRPTH16     3142 non-null   float64\n",
      " 45  LogTransformedRECFACPTH16  3142 non-null   float64\n",
      " 46  NEAREST_1                  3142 non-null   int64  \n",
      " 47  NEAREST_2                  3142 non-null   int64  \n",
      " 48  NEAREST_3                  3142 non-null   int64  \n",
      " 49  NEAREST_4                  3142 non-null   int64  \n",
      " 50  NEAREST_5                  3142 non-null   int64  \n",
      " 51  NEAREST_6                  3142 non-null   int64  \n",
      " 52  NEAREST_7                  3142 non-null   int64  \n",
      " 53  NEAREST_8                  3142 non-null   int64  \n",
      " 54  NEAREST_9                  3142 non-null   int64  \n",
      " 55  NEAREST_10                 3142 non-null   int64  \n",
      " 56  NEAREST_11                 3142 non-null   int64  \n",
      " 57  NEAREST_12                 3142 non-null   int64  \n",
      " 58  NEAREST_13                 3142 non-null   int64  \n",
      " 59  NEAREST_14                 3142 non-null   int64  \n",
      " 60  NEAREST_15                 3142 non-null   int64  \n",
      " 61  NEAREST_16                 3142 non-null   int64  \n",
      " 62  NEAREST_17                 3142 non-null   int64  \n",
      " 63  NEAREST_18                 3142 non-null   int64  \n",
      " 64  NEAREST_19                 3142 non-null   int64  \n",
      " 65  NEAREST_20                 3142 non-null   int64  \n",
      "dtypes: float64(39), int64(25), object(2)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# Merge with county census data / closest neighboring counties\n",
    "data = pd.merge(left = data.sort_values(by='FIPS'), right = closest_neighboring_counties.sort_values(by='FIPS'), how='inner')\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a366c75-7cbc-4e4c-a48f-82bf76d5f536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metro and nonmetro counties\n",
    "data_metro = data.loc[data['METRO13'] == 1].copy()\n",
    "data_nonmetro = data.loc[data['METRO13'] == 0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85175127-064c-4362-a00a-e25e311f5c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split with test size of 20%, the closest neighbors (max 20) are set as training data\n",
    "training_rows_per_test_row = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d114a1e-e00c-411e-b8b6-5fad595d6303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Designates 1 test sample for every training_rows_per_test_row training samples\n",
    "def remove_county_and_neighbors(df, remaining_indices, train_indices, test_indices):\n",
    "    \n",
    "    # Move next index to test set\n",
    "    i = remaining_indices[0]\n",
    "    county = df.iloc[i]\n",
    "    test_indices.append(i)\n",
    "    remaining_indices = remaining_indices[1:]\n",
    "    \n",
    "    # Move indices of closest neighboring counties to training set\n",
    "    a = 0\n",
    "    j = 0\n",
    "    while a < training_rows_per_test_row and j < MAX_NEIGHBORS:\n",
    "        neighbor_fips = county['NEAREST_' + str(j + 1)]\n",
    "        neighbor = df.loc[df['FIPS'] == neighbor_fips]\n",
    "        if len(neighbor.index > 0):\n",
    "            ind = neighbor.index[0]\n",
    "        else:\n",
    "            ind = -1\n",
    "        if ind in remaining_indices:\n",
    "            train_indices.append(ind)\n",
    "            remaining_indices.remove(ind)\n",
    "            a += 1\n",
    "        j += 1\n",
    "    # If all neighbors have been designated training or test, add additional neighbors to training set\n",
    "    while a < training_rows_per_test_row and len(remaining_indices) > 0:\n",
    "        train_indices.append(remaining_indices[0])\n",
    "        remaining_indices = remaining_indices[1:]\n",
    "        a += 1\n",
    "    return remaining_indices, train_indices, test_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7084e033-652b-4e8b-af25-634999950de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_preserving_train_test_split(df, slice):\n",
    "    remaining_indices = list(slice.index)\n",
    "    remaining_indices = list(np.random.permutation(remaining_indices))\n",
    "    train_indices = []\n",
    "    test_indices = []\n",
    "\n",
    "    # Iterate through shuffled indices, adding one row to the test set and training_rows_per_test_row rows as training samples\n",
    "    while len(remaining_indices) > 0:\n",
    "        remaining_indices, train_indices, test_indices = remove_county_and_neighbors(df, remaining_indices, train_indices, test_indices)\n",
    "    df_train = df.iloc[train_indices]\n",
    "    df_test = df.iloc[test_indices]\n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "970e3744-9054-4e05-af6f-29140cd1da93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train StandardScaler\n",
    "scaler = StandardScaler()\n",
    "categorical_variables = ['State','County','FIPS','PERPOV10','METRO13']\n",
    "categorical_data = data[categorical_variables]\n",
    "neighboring_counties_labels = ['NEAREST_' + str(j + 1) for j in range(MAX_NEIGHBORS)]\n",
    "neighboring_data = data[neighboring_counties_labels]\n",
    "noncategorical_data = data.drop(categorical_variables, axis=1).drop(neighboring_data, axis=1)\n",
    "noncategorical_labels = noncategorical_data.columns\n",
    "\n",
    "scaler.fit(noncategorical_data)\n",
    "\n",
    "data = pd.concat([categorical_data, noncategorical_data, neighboring_data],axis=1)\n",
    "split_categories = ['METRO13','PERPOV10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5347bab0-005d-467d-85dd-7f50c1af92c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_by_distances_and_categories(df, data_to_split, categories):\n",
    "    split_series = []\n",
    "    split_series.append([data_to_split])\n",
    "\n",
    "    training_slices = []\n",
    "    test_slices = []\n",
    "    for i in range(len(categories)):\n",
    "        split_series.append([])\n",
    "        for label in df[categories[i]].unique():\n",
    "            for data_to_slice in split_series[i]:\n",
    "                split_series[i+1].append(data_to_slice.loc[data_to_slice[categories[i]] == label].copy())\n",
    "    for split in split_series[-1]:\n",
    "        if len(split) > 0:\n",
    "            training_slice, test_slice = distance_preserving_train_test_split(df=df, slice=split)\n",
    "            training_slices.append(training_slice)\n",
    "            test_slices.append(test_slice)\n",
    "\n",
    "    return pd.concat(training_slices), pd.concat(test_slices)                                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca2f34c0-0d7b-4d78-94e2-ac9365ea0d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test = split_data_by_distances_and_categories(df=data, data_to_split=data, categories=split_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9068b9c5-2fbb-45d3-8848-7dad734bc83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export unscaled data\n",
    "data_train.drop(neighboring_counties_labels,axis=1).to_csv('../data/data_train_unscaled.csv', index=False)\n",
    "data_test.drop(neighboring_counties_labels,axis=1).to_csv('../data/data_test_unscaled.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef7c3a12-fd8a-4615-886b-b1c41047539a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now scale the data\n",
    "data_unscaled = pd.concat([data_train, data_test])\n",
    "\n",
    "categorical_data = data_unscaled[categorical_variables]\n",
    "neighboring_data = data_unscaled[neighboring_counties_labels]\n",
    "noncategorical_data = data_unscaled.drop(categorical_variables, axis=1).drop(neighboring_data, axis=1)\n",
    "noncategorical_labels = noncategorical_data.columns\n",
    "\n",
    "data_scaled = scaler.transform(noncategorical_data)\n",
    "noncategorical_data = pd.DataFrame(data_scaled, columns=noncategorical_labels)\n",
    "data = pd.concat([categorical_data, noncategorical_data, neighboring_data],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c5e15f1-537c-479a-a0ed-a4f2bb65e39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set aside scaled test data\n",
    "data_train = data.drop(data_test.index,axis=0).copy()\n",
    "data_test = data.loc[data_test.index].drop(neighboring_counties_labels, axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6736523-b75f-4836-8ef5-4e3d726c24c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sets for k-fold cross-validation\n",
    "k = 5\n",
    "\n",
    "data_to_k_split = data_train.copy()\n",
    "data_k_splits = []\n",
    "\n",
    "while k > 0:\n",
    "    training_rows_per_test_row = k - 1\n",
    "    data_remaining, data_split = split_data_by_distances_and_categories(df=data, data_to_split = data_to_k_split, categories=split_categories)\n",
    "    data_k_splits.append(data_split)\n",
    "    data_to_k_split = data_remaining.copy()\n",
    "    k = k - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "942c4ffc-93f8-45fa-8bcb-a84c8cfe5339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define holdout and training sets and drop closest neighbor data\n",
    "holdout_sets = [data_k_splits[i].drop(neighboring_counties_labels,axis=1) for i in range(len(data_k_splits))]\n",
    "training_sets = [pd.concat(holdout_sets[:i] + holdout_sets[i+1:]) for i in range(len(data_k_splits))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "feeee7fe-0535-4228-866e-747a9626e4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save training, test, and holdover data\n",
    "for i in range(len(holdout_sets)):\n",
    "    holdout_sets[i].to_csv('../data/data_holdout_' + str(i) + '.csv')\n",
    "    training_sets[i].to_csv('../data/data_train_' + str(i) + '.csv')\n",
    "data_test.to_csv('../data/data_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0beaf6ae-42f3-4931-8154-923f6709ea1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
